{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the libraries\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#old model\n",
    "model = keras.Sequential([\n",
    "  keras.layers.Rescaling(1./255),\n",
    "  keras.layers.Conv2D(32, (3,3), activation=\"relu\"),\n",
    "  keras.layers.MaxPooling2D(2),\n",
    "  keras.layers.Conv2D(64, (3,3), activation=\"relu\"),\n",
    "  keras.layers.MaxPooling2D(2),\n",
    "  keras.layers.Conv2D(128, (3,3), activation=\"relu\"),\n",
    "  keras.layers.MaxPooling2D(2),\n",
    "  keras.layers.Conv2D(128, (3,3), activation=\"relu\"),\n",
    "  keras.layers.MaxPooling2D(2),\n",
    "  keras.layers.Conv2D(256, (3,3), activation=\"relu\"),\n",
    "  keras.layers.Flatten(),\n",
    "  keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "\n",
    "  \n",
    "])\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA LOADING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the data\n",
    "definitions = pd.read_csv('OPTED-Dictionary.csv')\n",
    "simpDef1 = pd.read_excel('ChildFriendlyDefinitions.xlsx', sheet_name='Sheet1')\n",
    "simpDef2 = pd.read_json('data.json')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA PREPROCESSING (Everything below this only needs to be run once. A CSV will be created with the full dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def cleanDataframe(df):\n",
    "    df_copy = df\n",
    "\n",
    "    # may need to take the '-' out\n",
    "    regex = \"\\[(.*?)\\]|[0-9!@#$%^&*?\\/=+\\-]|\\((.*?)\\)|\\{(.*?)\\}|\\<(.*?)\\>\"\n",
    "\n",
    "    df_copy = df_copy.replace(to_replace=regex, value=\"\", regex=True).dropna()  # remove illegal chars\n",
    "    \n",
    "    df_copy.word = df_copy.word.str.lower()  # lower case everything\n",
    "    \n",
    "    df_copy = df_copy.sort_values('word', ascending=True)\n",
    "    df_copy = df_copy.drop_duplicates(subset='word', keep='first')\n",
    "    \n",
    "    return df_copy.reset_index().drop(['index'],axis=1)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "ACTUAL DEFINITIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>definition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'em</td>\n",
       "      <td>An obsolete or colloquial contraction of the o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'gainst</td>\n",
       "      <td>A contraction of Against.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'mongst</td>\n",
       "      <td>See Amongst.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'neath</td>\n",
       "      <td>An abbreviation of Beneath.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'s</td>\n",
       "      <td>A contraction for is or  for has.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111468</th>\n",
       "      <td>zymotic</td>\n",
       "      <td>Of  pertaining to or caused by fermentation.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111469</th>\n",
       "      <td>zyophyte</td>\n",
       "      <td>Any plant of a proposed class or grand divisio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111470</th>\n",
       "      <td>zythem</td>\n",
       "      <td>See Zythum.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111471</th>\n",
       "      <td>zythepsary</td>\n",
       "      <td>A brewery.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111472</th>\n",
       "      <td>zythum</td>\n",
       "      <td>A kind of ancient malt beverage; a liquor made...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111473 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              word                                         definition\n",
       "0              'em  An obsolete or colloquial contraction of the o...\n",
       "1          'gainst                          A contraction of Against.\n",
       "2          'mongst                                       See Amongst.\n",
       "3           'neath                        An abbreviation of Beneath.\n",
       "4               's                  A contraction for is or  for has.\n",
       "...            ...                                                ...\n",
       "111468     zymotic       Of  pertaining to or caused by fermentation.\n",
       "111469    zyophyte  Any plant of a proposed class or grand divisio...\n",
       "111470      zythem                                        See Zythum.\n",
       "111471  zythepsary                                         A brewery.\n",
       "111472      zythum  A kind of ancient malt beverage; a liquor made...\n",
       "\n",
       "[111473 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "definitions_filter = definitions.drop(['Count', 'POS'], axis=1)\n",
    "definitions_filter['word'] = definitions_filter['Word']\n",
    "definitions_filter['definition'] = definitions_filter['Definition']\n",
    "\n",
    "definitions_filter = definitions_filter.drop(['Word', 'Definition'], axis=1)\n",
    "definitions_filter = cleanDataframe(df=definitions_filter)\n",
    "\n",
    "regexQuote = \"^\\\"|\\\"$\"\n",
    "definitions_filter = definitions_filter.replace(to_replace=regexQuote, value=\"\", regex=True)\n",
    "definitions_filter\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SIMPLIFIED DEFINITIONS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>definition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accessible</td>\n",
       "      <td>When something is accessible it means anyone c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>accommodate</td>\n",
       "      <td>You accommodate when you change something that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>accomplish</td>\n",
       "      <td>If you accomplish something, you succeed in do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>achieve</td>\n",
       "      <td>If you achieve something, you succeed in doing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>acre</td>\n",
       "      <td>An acre is a very large area of land about the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>value</td>\n",
       "      <td>The value of a place or thing is how much mone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>verify</td>\n",
       "      <td>If you verify something, you make sure that it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>vigilant</td>\n",
       "      <td>Someone who is vigilant pays careful attention...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>visible</td>\n",
       "      <td>When something is visible, you can see it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>wish</td>\n",
       "      <td>When you wish for something, you think about s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>167 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            word                                         definition\n",
       "0     accessible  When something is accessible it means anyone c...\n",
       "1    accommodate  You accommodate when you change something that...\n",
       "2     accomplish  If you accomplish something, you succeed in do...\n",
       "3        achieve  If you achieve something, you succeed in doing...\n",
       "4           acre  An acre is a very large area of land about the...\n",
       "..           ...                                                ...\n",
       "162        value  The value of a place or thing is how much mone...\n",
       "163       verify  If you verify something, you make sure that it...\n",
       "164     vigilant  Someone who is vigilant pays careful attention...\n",
       "165      visible         When something is visible, you can see it.\n",
       "166         wish  When you wish for something, you think about s...\n",
       "\n",
       "[167 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Filter simpDef1\n",
    "simpDef1_Filter = simpDef1.drop(['Exemplar'], axis=1)\n",
    "simpDef1_Filter['word'] = simpDef1_Filter['Word']\n",
    "simpDef1_Filter['definition'] = simpDef1_Filter['Child Friendly Definition']\n",
    "simpDef1_Filter = simpDef1_Filter.drop(\n",
    "    ['Word', 'Child Friendly Definition'], axis=1)\n",
    "simpDef1_Filter = cleanDataframe(simpDef1_Filter)\n",
    "simpDef1_Filter\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>definition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'s</td>\n",
       "      <td>a suffix used to form the possessive of most s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'tis</td>\n",
       "      <td>shortened form of \"it is.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'twas</td>\n",
       "      <td>shortened form of \"it was.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>the first letter of the English alphabet.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a dime a dozen</td>\n",
       "      <td>plentiful and easy to get; common; cheap.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13907</th>\n",
       "      <td>zone</td>\n",
       "      <td>an area that is divided from other areas becau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13908</th>\n",
       "      <td>zoo</td>\n",
       "      <td>a place where living animals, especially wild ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13909</th>\n",
       "      <td>zoology</td>\n",
       "      <td>the science and study of animals.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13910</th>\n",
       "      <td>zoom</td>\n",
       "      <td>to move quickly while making a low humming sou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13911</th>\n",
       "      <td>zucchini</td>\n",
       "      <td>a type of summer squash that is shaped like a ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13912 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 word                                         definition\n",
       "0                  's  a suffix used to form the possessive of most s...\n",
       "1                'tis                         shortened form of \"it is.\"\n",
       "2               'twas                        shortened form of \"it was.\"\n",
       "3                   a         the first letter of the English alphabet. \n",
       "4      a dime a dozen          plentiful and easy to get; common; cheap.\n",
       "...               ...                                                ...\n",
       "13907            zone  an area that is divided from other areas becau...\n",
       "13908             zoo  a place where living animals, especially wild ...\n",
       "13909         zoology                  the science and study of animals.\n",
       "13910            zoom  to move quickly while making a low humming sou...\n",
       "13911        zucchini  a type of summer squash that is shaped like a ...\n",
       "\n",
       "[13912 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simpDef2_filter = simpDef2\n",
    "simpDef2_Filter = cleanDataframe(simpDef2_filter)\n",
    "simpDef2_Filter\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting Dataset ready for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>definition</th>\n",
       "      <th>simplified_definition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accessible</td>\n",
       "      <td>Easy of access or approach; approachable; as  ...</td>\n",
       "      <td>When something is accessible it means anyone c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>accommodate</td>\n",
       "      <td>To render fit  suitable or correspondent; to a...</td>\n",
       "      <td>You accommodate when you change something that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>accomplish</td>\n",
       "      <td>To complete  as time or distance.</td>\n",
       "      <td>If you accomplish something, you succeed in do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>achieve</td>\n",
       "      <td>To finish; to kill.</td>\n",
       "      <td>If you achieve something, you succeed in doing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>acre</td>\n",
       "      <td>A piece of land  containing  square rods or   ...</td>\n",
       "      <td>An acre is a very large area of land about the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10913</th>\n",
       "      <td>zither</td>\n",
       "      <td>An instrument of music used in Austria and Ger...</td>\n",
       "      <td>a stringed instrument that has a flat sound bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10914</th>\n",
       "      <td>zodiac</td>\n",
       "      <td>An imaginary belt in the heavens   or  broad i...</td>\n",
       "      <td>an imaginary belt in the heavens that includes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10915</th>\n",
       "      <td>zone</td>\n",
       "      <td>Circuit; circumference.</td>\n",
       "      <td>an area that is divided from other areas becau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10916</th>\n",
       "      <td>zoo</td>\n",
       "      <td>A combining form from Gr. zwo n an animal as i...</td>\n",
       "      <td>a place where living animals, especially wild ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10917</th>\n",
       "      <td>zoology</td>\n",
       "      <td>That part of biology which relates to the anim...</td>\n",
       "      <td>the science and study of animals.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10918 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              word                                         definition  \\\n",
       "0       accessible  Easy of access or approach; approachable; as  ...   \n",
       "1      accommodate  To render fit  suitable or correspondent; to a...   \n",
       "2       accomplish                  To complete  as time or distance.   \n",
       "3          achieve                                To finish; to kill.   \n",
       "4             acre  A piece of land  containing  square rods or   ...   \n",
       "...            ...                                                ...   \n",
       "10913       zither  An instrument of music used in Austria and Ger...   \n",
       "10914       zodiac  An imaginary belt in the heavens   or  broad i...   \n",
       "10915         zone                            Circuit; circumference.   \n",
       "10916          zoo  A combining form from Gr. zwo n an animal as i...   \n",
       "10917      zoology  That part of biology which relates to the anim...   \n",
       "\n",
       "                                   simplified_definition  \n",
       "0      When something is accessible it means anyone c...  \n",
       "1      You accommodate when you change something that...  \n",
       "2      If you accomplish something, you succeed in do...  \n",
       "3      If you achieve something, you succeed in doing...  \n",
       "4      An acre is a very large area of land about the...  \n",
       "...                                                  ...  \n",
       "10913  a stringed instrument that has a flat sound bo...  \n",
       "10914  an imaginary belt in the heavens that includes...  \n",
       "10915  an area that is divided from other areas becau...  \n",
       "10916  a place where living animals, especially wild ...  \n",
       "10917                  the science and study of animals.  \n",
       "\n",
       "[10918 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Basically we are combining all the dataset together and putting it into a csv\n",
    "#Doing this because i don't want to constantly run this script (takes up RAM that I dont have)\n",
    "\n",
    "df = pd.DataFrame(columns=['word','definition', 'simplified_definition'])\n",
    "\n",
    "for index, row in simpDef1_Filter.iterrows():\n",
    "    defs = definitions_filter[row['word'] == definitions_filter.word]['definition']\n",
    "    if defs.count() >= 1:\n",
    "        w = row['word']\n",
    "        simpDefs = row['definition']\n",
    "        defs = defs.values[0]\n",
    "        df = pd.concat([df, pd.DataFrame([[w, defs, simpDefs]], columns=['word', 'definition', 'simplified_definition'])], ignore_index=True)\n",
    "\n",
    "for index, row in simpDef2_Filter.iterrows():\n",
    "    defs = definitions_filter[row['word'] ==\n",
    "                              definitions_filter.word]['definition']\n",
    "    if defs.count() >= 1:\n",
    "        w = row['word']\n",
    "        simpDefs = row['definition']\n",
    "        defs = defs.values[0]\n",
    "        df = pd.concat([df, pd.DataFrame([[w, defs, simpDefs]], columns=[\n",
    "                       'word', 'definition', 'simplified_definition'])], ignore_index=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df\u001b[39m.\u001b[39mto_csv(\u001b[39m\"\u001b[39m\u001b[39mfullDataset.csv\u001b[39m\u001b[39m\"\u001b[39m, index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.to_csv(\"fullDataset.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load csv\n",
    "fullDs = pd.read_csv(\"fullDataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def convertTextToNumbers(words, tokenizer=None, padding=None, isTrainY=False):\n",
    "    # Create a tokenizer and fit it on the entire text corpus\n",
    "    if tokenizer==None:\n",
    "        #tokenizer = Tokenizer(split=' ')\n",
    "        tokenizer = Tokenizer()\n",
    "        tokenizer.fit_on_texts(words)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    # Convert the text to sequences of integers\n",
    "    sequences = tokenizer.texts_to_sequences(words)\n",
    "\n",
    "    if isTrainY:\n",
    "        tokenizer.word_index['<start>'] = len(\n",
    "            tokenizer.word_index) + 1\n",
    "        tokenizer.word_index['<end>'] = len(\n",
    "            tokenizer.word_index) + 1\n",
    "        sequences = [[tokenizer.word_index['<start>']] +\n",
    "                              seq + [tokenizer.word_index['<end>']] for seq in sequences]\n",
    "\n",
    "    # Get the word index mapping\n",
    "    word_index = tokenizer.word_index\n",
    "\n",
    "    # Making sure all inputs are of the same length\n",
    "    if padding==None:\n",
    "        sequences = tf.keras.preprocessing.sequence.pad_sequences(sequences, padding='post')\n",
    "    else:\n",
    "        sequences = tf.keras.preprocessing.sequence.pad_sequences(sequences, maxlen=padding, padding='post')\n",
    "    return (sequences, word_index, tokenizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input data\n",
    "input_texts = ['dog is an animal', 'cat is a mammal', 'fish lives in water']\n",
    "simplified_texts = ['dog is animal', 'cat is mammal', 'fish lives in water']\n",
    "\n",
    "# Tokenize input and output data\n",
    "input_tokenizer = Tokenizer()\n",
    "input_tokenizer.fit_on_texts(input_texts)\n",
    "input_seq = input_tokenizer.texts_to_sequences(input_texts)\n",
    "max_len_input = max(len(seq) for seq in input_seq)\n",
    "input_pad_seq = pad_sequences(input_seq, maxlen=max_len_input, padding='post')\n",
    "\n",
    "simp_eng_tokenizer = Tokenizer()\n",
    "simp_eng_tokenizer.fit_on_texts(simplified_texts)\n",
    "simp_eng_seq = simp_eng_tokenizer.texts_to_sequences(simplified_texts)\n",
    "max_len_output = max(len(seq) for seq in simp_eng_seq)\n",
    "simp_eng_pad_seq = pad_sequences(simp_eng_seq, maxlen=max_len_output, padding='post')\n",
    "\n",
    "# Add start and end tokens to decoder input and target data\n",
    "decoder_input_data = np.zeros((len(simplified_texts), max_len_output), dtype='int32')\n",
    "decoder_target_data = np.zeros((len(simplified_texts), max_len_output, len(simp_eng_tokenizer.word_index) + 1), dtype='float32')\n",
    "\n",
    "\n",
    "for i, text in enumerate(simplified_texts):\n",
    "    tokens = ['<start>'] + text.split() + ['<end>']\n",
    "    for j, token in enumerate(tokens):\n",
    "        decoder_input_data[i, j] = simp_eng_tokenizer.word_index.get(token, 0)\n",
    "        if j > 0:\n",
    "            k = simp_eng_tokenizer.word_index.get(token, 0)\n",
    "            decoder_target_data[i, j - 1, k] = 1.0\n",
    "\n",
    "# Print example input and target data for the first sample\n",
    "print('Encoder input data:', input_pad_seq[0])\n",
    "print('Decoder input data:', decoder_input_data[0])\n",
    "print('Decoder target data:')\n",
    "for j in range(max_len_output):\n",
    "    print(simp_eng_tokenizer.index_word[np.argmax(decoder_target_data[0, j])], end=' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split training set (do not need test) - we will provide a definition and evaluate it ourselves\n",
    "# we also may not need a validation set since i dont know if it will evaluate it properly.\n",
    "fullDs = fullDs.sample(frac=1) # shuffle the dataset\n",
    "fullDs = fullDs.astype(str)\n",
    "\n",
    "# the two arrays below are tokenized and padded for the algorithm\n",
    "full_train_x, defWordIndex, defTokenizer = convertTextToNumbers(\n",
    "    fullDs['definition'].values[0:1000])\n",
    "\n",
    "full_train_y, simpDefWordIndex, simpDefTokenizer = convertTextToNumbers(\n",
    "    fullDs['simplified_definition'].values[0:1000], isTrainY=True)\n",
    "\n",
    "full_train_y_RAW = fullDs['simplified_definition'].values[0:1000]\n",
    "#decoder_target_data_y = createOneHotEncodingVector(full_train_y, len(simpDefWordIndex), simpDefWordIndex)\n",
    "#full_train_x = full_train_x.astype('int')\n",
    "#full_train_y = full_train_y.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>definition</th>\n",
       "      <th>simplified_definition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3832</th>\n",
       "      <td>fellowship</td>\n",
       "      <td>A state of being together; companionship; part...</td>\n",
       "      <td>the condition of being companions; company or ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9352</th>\n",
       "      <td>stamina</td>\n",
       "      <td>See Stamen.</td>\n",
       "      <td>the strength to handle long effort or disappoi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>blemish</td>\n",
       "      <td>To mark with deformity; to injure or impair  a...</td>\n",
       "      <td>to damage or spoil the perfection of.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935</th>\n",
       "      <td>azure</td>\n",
       "      <td>Skyblue; resembling the clear blue color of th...</td>\n",
       "      <td>the color of a clear blue sky.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3856</th>\n",
       "      <td>fib</td>\n",
       "      <td>To speak falsely.</td>\n",
       "      <td>a lie about something that is not important.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>azalea</td>\n",
       "      <td>A genus of showy flowering shrubs  mostly nati...</td>\n",
       "      <td>a shrub with dark green leaves and brightly co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9050</th>\n",
       "      <td>slit</td>\n",
       "      <td>d. pers. sing. pres. of Slide.</td>\n",
       "      <td>to cut a long straight line into or through.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6422</th>\n",
       "      <td>molding</td>\n",
       "      <td>Alt. of Moulding</td>\n",
       "      <td>the act of shaping or forming something.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9121</th>\n",
       "      <td>snuffbox</td>\n",
       "      <td>A small box for carrying snuff about the person.</td>\n",
       "      <td>a small box for holding tobacco in powdered form.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2083</th>\n",
       "      <td>coloring</td>\n",
       "      <td>of Color</td>\n",
       "      <td>something used to give color to.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10918 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            word                                         definition  \\\n",
       "3832  fellowship  A state of being together; companionship; part...   \n",
       "9352     stamina                                        See Stamen.   \n",
       "1239     blemish  To mark with deformity; to injure or impair  a...   \n",
       "935        azure  Skyblue; resembling the clear blue color of th...   \n",
       "3856         fib                                  To speak falsely.   \n",
       "...          ...                                                ...   \n",
       "933       azalea  A genus of showy flowering shrubs  mostly nati...   \n",
       "9050        slit                     d. pers. sing. pres. of Slide.   \n",
       "6422     molding                                   Alt. of Moulding   \n",
       "9121    snuffbox   A small box for carrying snuff about the person.   \n",
       "2083    coloring                                           of Color   \n",
       "\n",
       "                                  simplified_definition  \n",
       "3832  the condition of being companions; company or ...  \n",
       "9352  the strength to handle long effort or disappoi...  \n",
       "1239             to damage or spoil the perfection of.   \n",
       "935                     the color of a clear blue sky.   \n",
       "3856      a lie about something that is not important.   \n",
       "...                                                 ...  \n",
       "933   a shrub with dark green leaves and brightly co...  \n",
       "9050      to cut a long straight line into or through.   \n",
       "6422          the act of shaping or forming something.   \n",
       "9121  a small box for holding tobacco in powdered form.  \n",
       "2083                  something used to give color to.   \n",
       "\n",
       "[10918 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   3,   34,    2,   27,  180, 1542, 1543,  504,   44,  801, 1544,\n",
       "        505,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0], dtype=int32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_train_x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8993,  733,   44,    3, 8994,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0], dtype=int32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_train_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10918\n",
      "800\n",
      "800\n",
      "200\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "train_ratio = 0.8\n",
    "\n",
    "# Split the DataFrame into training and validation sets\n",
    "train_x = full_train_x[:int(len(full_train_x) * train_ratio)]\n",
    "train_y = full_train_y[:int(len(full_train_y) * train_ratio)]\n",
    "val_x = full_train_x[int(len(full_train_x) * train_ratio):]\n",
    "val_y = full_train_y[int(len(full_train_y) * train_ratio):]\n",
    "\n",
    "# Convert the Pandas DataFrame to TensorFlow Dataset\n",
    "#train_ds = tf.data.Dataset.from_tensor_slices((train_df.values[:, :-1], train_df.values[:, -1]))\n",
    "#val_ds = tf.data.Dataset.from_tensor_slices((val_df.values[:, :-1], val_df.values[:, -1]))\n",
    "print(len(fullDs['definition'])) # 10918\n",
    "print(len(train_x)) # 8734\n",
    "print(len(train_y)) # 8734\n",
    "print(len(val_x)) # 2184\n",
    "print(len(val_y)) # 2184\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   3   34    2   27  180 1542 1543  504   44  801 1544  505    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0]\n",
      "[2726    4   51    5   43 1112  363    2 1113    3 2727    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0]\n",
      "a state of being together companionship partnership association hence confederation joint interest\n",
      "the condition of being companions company or friendship  \n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>definition</th>\n",
       "      <th>simplified_definition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3832</th>\n",
       "      <td>fellowship</td>\n",
       "      <td>A state of being together; companionship; part...</td>\n",
       "      <td>the condition of being companions; company or ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            word                                         definition  \\\n",
       "3832  fellowship  A state of being together; companionship; part...   \n",
       "\n",
       "                                  simplified_definition  \n",
       "3832  the condition of being companions; company or ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(full_train_x[0]) # def (should be head(1))\n",
    "print(full_train_y[0]) # simp def\n",
    "\n",
    "print(defTokenizer.sequences_to_texts([full_train_x[0]])[0])\n",
    "print(simpDefTokenizer.sequences_to_texts([full_train_y[0]])[0])\n",
    "print(\"\\n\\n\\n\")\n",
    "fullDs.head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18407\n",
      "8994\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, None, 100)    1840700     ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, None, 100)    899400      ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    [(None, 170),        184280      ['embedding[0][0]']              \n",
      "                                 (None, 170),                                                     \n",
      "                                 (None, 170)]                                                     \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, None, 170),  184280      ['embedding_1[0][0]',            \n",
      "                                 (None, 170),                     'lstm[0][1]',                   \n",
      "                                 (None, 170)]                     'lstm[0][2]']                   \n",
      "                                                                                                  \n",
      " time_distributed (TimeDistribu  (None, None, 8994)  1537974     ['lstm_1[0][0]']                 \n",
      " ted)                                                                                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,646,634\n",
      "Trainable params: 4,646,634\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding, Flatten, TimeDistributed, Lambda\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from keras import backend as K\n",
    "\n",
    "def createModel(encoding_token, decoding_token, embedding_dim, latent_dim):\n",
    "\n",
    "\n",
    "    # Define input sequence\n",
    "    inputs = Input(shape=(None,))\n",
    "\n",
    "\n",
    "    # Define encoder embedding layer\n",
    "    enc_emb = Embedding(input_dim=encoding_token, output_dim=embedding_dim)(inputs)\n",
    "\n",
    "    \n",
    "    # Define encoder LSTM\n",
    "    encoder_lstm = LSTM(latent_dim, return_state=True)\n",
    "    _, state_h, state_c = encoder_lstm(enc_emb)\n",
    "\n",
    "\n",
    "    # Discard encoder outputs and only keep states\n",
    "    encoder_states = [state_h, state_c]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Define decoder input sequence\n",
    "    decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "\n",
    "    # Define decoder embedding layer\n",
    "    dec_emb_layer = Embedding(input_dim=decoding_token, output_dim=embedding_dim)\n",
    "    dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "\n",
    "    # Define decoder LSTM\n",
    "    decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "    decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=encoder_states)\n",
    "\n",
    "    # Define decoder output layer\n",
    "    #flat = Flatten()(decoder_outputs)\n",
    "\n",
    "    #decoder_dense = Dense(decoding_token, activation='softmax')\n",
    "\n",
    "    decoder_dense = TimeDistributed(Dense(decoding_token, activation='linear'))\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "\n",
    "\n",
    "    # Define the model\n",
    "    model = Model([inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "    return model\n",
    "\n",
    "\n",
    "encoding_token = len(defWordIndex)\n",
    "decoding_token = len(simpDefWordIndex)\n",
    "print(encoding_token)\n",
    "print(decoding_token)\n",
    "# usually 50 - 500 higher = more complex relation but higher chance of overfitting.\n",
    "embedding_dim = 100\n",
    "# usually 128 - 256 higher = more complex relation but higher chance of overfitting.\n",
    "latent_dim = 170\n",
    "model = createModel(encoding_token=encoding_token, decoding_token=decoding_token,\n",
    "                    embedding_dim=embedding_dim, latent_dim=latent_dim)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4542\n",
      "2728\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding_2 (Embedding)        (None, None, 1)      4542        ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_3 (Embedding)        (None, None, 1)      2728        ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)                  [(None, 1),          12          ['embedding_2[0][0]']            \n",
      "                                 (None, 1),                                                       \n",
      "                                 (None, 1)]                                                       \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)                  [(None, None, 1),    12          ['embedding_3[0][0]',            \n",
      "                                 (None, 1),                       'lstm_2[0][1]',                 \n",
      "                                 (None, 1)]                       'lstm_2[0][2]']                 \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, None, 2728)   5456        ['lstm_3[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 12,750\n",
      "Trainable params: 12,750\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#use this one\n",
    "\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding, Flatten, TimeDistributed, Lambda\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "def createModel(encoding_token, decoding_token, embedding_dim, latent_dim):\n",
    "\n",
    "    # Define input sequence\n",
    "    inputs = Input(shape=(None,))\n",
    "\n",
    "    # Define encoder embedding layer\n",
    "    enc_emb = Embedding(encoding_token, latent_dim, mask_zero=True)(inputs)\n",
    "\n",
    "    # Define encoder LSTM\n",
    "    encoder_lstm = LSTM(latent_dim, return_state=True)\n",
    "    _, state_h, state_c = encoder_lstm(enc_emb)\n",
    "\n",
    "    # Discard encoder outputs and only keep states\n",
    "    encoder_states = [state_h, state_c]\n",
    "\n",
    "    # Define decoder input sequence\n",
    "    decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "    # Define decoder embedding layer\n",
    "    dec_emb_layer = Embedding(decoding_token,\n",
    "                              output_dim=embedding_dim)\n",
    "    dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "    # Define decoder LSTM\n",
    "    decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "    decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=encoder_states)\n",
    "\n",
    "    # Define decoder output layer\n",
    "    # flat = Flatten()(decoder_outputs)\n",
    "\n",
    "    # decoder_dense = Dense(decoding_token, activation='softmax')\n",
    "\n",
    "    decoder_dense = Dense(decoding_token, activation='softmax')\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "    # Define the model\n",
    "    model = Model([inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "    return model\n",
    "\n",
    "\n",
    "encoding_token = len(defWordIndex) + 1\n",
    "decoding_token = len(simpDefWordIndex) + 1\n",
    "print(encoding_token)\n",
    "print(decoding_token)\n",
    "# usually 50 - 500 higher = more complex relation but higher chance of overfitting.\n",
    "embedding_dim = 1\n",
    "# usually 128 - 256 higher = more complex relation but higher chance of overfitting.\n",
    "latent_dim = 1\n",
    "model = createModel(encoding_token=encoding_token, decoding_token=decoding_token,\n",
    "                    embedding_dim=embedding_dim, latent_dim=latent_dim)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_train_y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10918"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n",
      "condition\n",
      "of\n",
      "being\n",
      "companions;\n",
      "company\n",
      "or\n",
      "friendship. \n",
      "the\n",
      "strength\n",
      "to\n",
      "handle\n",
      "long\n",
      "effort\n",
      "or\n",
      "disappointment.\n",
      "to\n",
      "damage\n",
      "or\n",
      "spoil\n",
      "the\n",
      "perfection\n",
      "of. \n",
      "the\n",
      "color\n",
      "of\n",
      "a\n",
      "clear\n",
      "blue\n",
      "sky. \n",
      "a\n",
      "lie\n",
      "about\n",
      "something\n",
      "that\n",
      "is\n",
      "not\n",
      "important. \n",
      "seeming\n",
      "likely\n",
      "to\n",
      "succeed\n",
      "or\n",
      "turn\n",
      "out\n",
      "well\n",
      "in\n",
      "the\n",
      "future.\n",
      "of\n",
      "or\n",
      "having\n",
      "to\n",
      "do\n",
      "with\n",
      "the\n",
      "moon.\n",
      "a\n",
      "bird\n",
      "that\n",
      "lives\n",
      "in\n",
      "or\n",
      "near\n",
      "water\n",
      "and\n",
      "has\n",
      "webbed\n",
      "feet\n",
      "for\n",
      "swimming\n",
      "and\n",
      "a\n",
      "large\n",
      "flat\n",
      "bill. \n",
      "the\n",
      "waves\n",
      "of\n",
      "energy\n",
      "sent\n",
      "out\n",
      "by\n",
      "sources\n",
      "of\n",
      "heat\n",
      "or\n",
      "light,\n",
      "or\n",
      "by\n",
      "radioactive\n",
      "material.\n",
      "not\n",
      "able\n",
      "to\n",
      "feel;\n",
      "lacking\n",
      "in\n",
      "feeling\n",
      "or\n",
      "movement. \n"
     ]
    }
   ],
   "source": [
    "for index, sentence in enumerate(full_train_y_RAW[0:10]):\n",
    "    tokens = sentence.split(' ')\n",
    "    for j, token in enumerate(tokens):\n",
    "        print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU') \n",
    "for gpu in gpus: \n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(input_sequences, target_sequences, target_RAW, batch_size, simpWordIndex, wordSize):\n",
    "    while True:\n",
    "        for i in range(0, len(target_RAW), batch_size):\n",
    "\n",
    "            \n",
    "            decoder_target_data = np.zeros((batch_size, wordSize, len(simpWordIndex)+50), dtype='float32')\n",
    "            for index, sentence in enumerate(target_RAW[i:i+batch_size]):\n",
    "                print(sentence)\n",
    "                tokens = sentence.split(' ')\n",
    "                for j, token in enumerate(tokens):\n",
    "                    temp = simpWordIndex.get(token, 0)\n",
    "                    if temp > 0:\n",
    "\n",
    "                        decoder_target_data[index, j, temp] = 1.0\n",
    "                        \n",
    "\n",
    "\n",
    "\n",
    "            yield [input_sequences, target_sequences], decoder_target_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the condition of being companions; company or friendship. \n",
      "Epoch 1/10\n",
      "the strength to handle long effort or disappointment.\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'categorical_crossentropy/softmax_cross_entropy_with_logits' defined at (most recent call last):\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 619, in start\n      self.io_loop.start()\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/tornado/ioloop.py\", line 688, in <lambda>\n      lambda f: self._run_callback(functools.partial(callback, future))\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/tornado/ioloop.py\", line 741, in _run_callback\n      ret = callback()\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/tornado/gen.py\", line 814, in inner\n      self.ctx_run(self.run)\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/tornado/gen.py\", line 775, in run\n      yielded = self.gen.send(value)\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 358, in process_one\n      yield gen.maybe_future(dispatch(*args))\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n      yield gen.maybe_future(handler(stream, idents, msg))\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 536, in execute_request\n      self.do_execute(\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_cell\n      result = self._run_cell(\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3016, in _run_cell\n      result = runner(coro)\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3221, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3400, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3460, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-17-08205bf52681>\", line 5, in <module>\n      model.fit(generator, epochs=10)\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1650, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1249, in train_function\n      return step_function(self, iterator)\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1233, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1024, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1082, in compute_loss\n      return self.compiled_loss(\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/compile_utils.py\", line 265, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/keras/losses.py\", line 152, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/keras/losses.py\", line 284, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/keras/losses.py\", line 2004, in categorical_crossentropy\n      return backend.categorical_crossentropy(\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/keras/backend.py\", line 5538, in categorical_crossentropy\n      return tf.nn.softmax_cross_entropy_with_logits(\nNode: 'categorical_crossentropy/softmax_cross_entropy_with_logits'\nlogits and labels must be broadcastable: logits_size=[78000,2728] labels_size=[78,2777]\n\t [[{{node categorical_crossentropy/softmax_cross_entropy_with_logits}}]] [Op:__inference_train_function_20622]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m steps_per_epoch \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(full_train_x) \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m batch_size\n\u001b[1;32m      4\u001b[0m generator \u001b[39m=\u001b[39m data_generator(full_train_x, full_train_y, full_train_y_RAW, batch_size, simpDefWordIndex, \u001b[39mlen\u001b[39m(full_train_y[\u001b[39m0\u001b[39m]))\n\u001b[0;32m----> 5\u001b[0m model\u001b[39m.\u001b[39;49mfit(generator, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'categorical_crossentropy/softmax_cross_entropy_with_logits' defined at (most recent call last):\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 619, in start\n      self.io_loop.start()\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/tornado/ioloop.py\", line 688, in <lambda>\n      lambda f: self._run_callback(functools.partial(callback, future))\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/tornado/ioloop.py\", line 741, in _run_callback\n      ret = callback()\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/tornado/gen.py\", line 814, in inner\n      self.ctx_run(self.run)\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/tornado/gen.py\", line 775, in run\n      yielded = self.gen.send(value)\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 358, in process_one\n      yield gen.maybe_future(dispatch(*args))\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n      yield gen.maybe_future(handler(stream, idents, msg))\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 536, in execute_request\n      self.do_execute(\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_cell\n      result = self._run_cell(\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3016, in _run_cell\n      result = runner(coro)\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3221, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3400, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3460, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-17-08205bf52681>\", line 5, in <module>\n      model.fit(generator, epochs=10)\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1650, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1249, in train_function\n      return step_function(self, iterator)\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1233, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1024, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1082, in compute_loss\n      return self.compiled_loss(\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/compile_utils.py\", line 265, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/keras/losses.py\", line 152, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/keras/losses.py\", line 284, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/keras/losses.py\", line 2004, in categorical_crossentropy\n      return backend.categorical_crossentropy(\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/keras/backend.py\", line 5538, in categorical_crossentropy\n      return tf.nn.softmax_cross_entropy_with_logits(\nNode: 'categorical_crossentropy/softmax_cross_entropy_with_logits'\nlogits and labels must be broadcastable: logits_size=[78000,2728] labels_size=[78,2777]\n\t [[{{node categorical_crossentropy/softmax_cross_entropy_with_logits}}]] [Op:__inference_train_function_20622]"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 1\n",
    "steps_per_epoch = len(full_train_x) // batch_size\n",
    "\n",
    "generator = data_generator(full_train_x, full_train_y, full_train_y_RAW, batch_size, simpDefWordIndex, len(full_train_y[0]))\n",
    "model.fit(generator, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createOneHotEncodingVector(simpDef, maxLengthOutput, wordIndex):\n",
    "    decoder_target_data = np.zeros(\n",
    "        (len(simpDef), maxLengthOutput, len(wordIndex) + 1), dtype='float32')\n",
    "    for i, word in enumerate(simpDef):\n",
    "        for j, token in enumerate(word):\n",
    "            index = wordIndex.get(token, 0)\n",
    "            if index > 0:\n",
    "                decoder_target_data[i, j-1, index] == 1.0\n",
    "    return decoder_target_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_train_y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8993,    1, 1374, 1275,   17,  357,  310,    9,   10,  163,   14,\n",
       "       1194,    4,   34,    3, 8994,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0], dtype=int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_train_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1,\n",
       " 'or': 2,\n",
       " '\\xa0': 3,\n",
       " 'of': 4,\n",
       " 'the': 5,\n",
       " 'to': 6,\n",
       " 'and': 7,\n",
       " 'in': 8,\n",
       " 'that': 9,\n",
       " 'is': 10,\n",
       " 'with': 11,\n",
       " 'for': 12,\n",
       " 'are': 13,\n",
       " 'by': 14,\n",
       " 'an': 15,\n",
       " 'used': 16,\n",
       " 'from': 17,\n",
       " 'something': 18,\n",
       " 'as': 19,\n",
       " 'on': 20,\n",
       " 'other': 21,\n",
       " 'person': 22,\n",
       " 'not': 23,\n",
       " 'one': 24,\n",
       " 'having': 25,\n",
       " 'who': 26,\n",
       " 'it': 27,\n",
       " 'be': 28,\n",
       " 'made': 29,\n",
       " 'has': 30,\n",
       " 'make': 31,\n",
       " 'small': 32,\n",
       " 'do': 33,\n",
       " 'people': 34,\n",
       " 'act': 35,\n",
       " 'at': 36,\n",
       " 'large': 37,\n",
       " 'long': 38,\n",
       " 'being': 39,\n",
       " 'like': 40,\n",
       " 'have': 41,\n",
       " 'into': 42,\n",
       " 'past': 43,\n",
       " 'water': 44,\n",
       " 'way': 45,\n",
       " 'body': 46,\n",
       " 'place': 47,\n",
       " 'can': 48,\n",
       " 'which': 49,\n",
       " 'very': 50,\n",
       " 'part': 51,\n",
       " 'they': 52,\n",
       " 'things': 53,\n",
       " 'you': 54,\n",
       " 'up': 55,\n",
       " 'another': 56,\n",
       " 'out': 57,\n",
       " 'such': 58,\n",
       " 'time': 59,\n",
       " 'its': 60,\n",
       " 'group': 61,\n",
       " 'often': 62,\n",
       " 'when': 63,\n",
       " 'two': 64,\n",
       " 'some': 65,\n",
       " 'live': 66,\n",
       " 'animal': 67,\n",
       " 'animals': 68,\n",
       " 'plant': 69,\n",
       " 'short': 70,\n",
       " 'about': 71,\n",
       " 'many': 72,\n",
       " 'between': 73,\n",
       " 'usually': 74,\n",
       " 'food': 75,\n",
       " 'without': 76,\n",
       " 'through': 77,\n",
       " 'more': 78,\n",
       " 'over': 79,\n",
       " 'someone': 80,\n",
       " 'form': 81,\n",
       " 'piece': 82,\n",
       " 'together': 83,\n",
       " 'kinds': 84,\n",
       " 'hard': 85,\n",
       " 'cause': 86,\n",
       " 'strong': 87,\n",
       " 'tense': 88,\n",
       " 'condition': 89,\n",
       " 'light': 90,\n",
       " 'parts': 91,\n",
       " 'state': 92,\n",
       " 'their': 93,\n",
       " 'particular': 94,\n",
       " 'thing': 95,\n",
       " 'all': 96,\n",
       " 'move': 97,\n",
       " 'no': 98,\n",
       " 'but': 99,\n",
       " 'use': 100,\n",
       " 'participle': 101,\n",
       " 'give': 102,\n",
       " 'certain': 103,\n",
       " 'area': 104,\n",
       " \"one's\": 105,\n",
       " 'flat': 106,\n",
       " 'related': 107,\n",
       " 'surface': 108,\n",
       " 'feeling': 109,\n",
       " 'material': 110,\n",
       " 'metal': 111,\n",
       " 'where': 112,\n",
       " 'sound': 113,\n",
       " 'than': 114,\n",
       " 'different': 115,\n",
       " 'what': 116,\n",
       " 'amount': 117,\n",
       " 'work': 118,\n",
       " 'money': 119,\n",
       " 'back': 120,\n",
       " 'around': 121,\n",
       " 'great': 122,\n",
       " 'thin': 123,\n",
       " 'soft': 124,\n",
       " 'able': 125,\n",
       " 'same': 126,\n",
       " 'any': 127,\n",
       " 'liquid': 128,\n",
       " 'word': 129,\n",
       " 'end': 130,\n",
       " 'take': 131,\n",
       " 'building': 132,\n",
       " 'head': 133,\n",
       " 'white': 134,\n",
       " 'found': 135,\n",
       " 'land': 136,\n",
       " 'plants': 137,\n",
       " 'after': 138,\n",
       " 'others': 139,\n",
       " 'air': 140,\n",
       " 'makes': 141,\n",
       " 'making': 142,\n",
       " 'legs': 143,\n",
       " 'north': 144,\n",
       " 'country': 145,\n",
       " 'order': 146,\n",
       " 'using': 147,\n",
       " 'if': 148,\n",
       " 'away': 149,\n",
       " 'process': 150,\n",
       " 'number': 151,\n",
       " 'skin': 152,\n",
       " 'off': 153,\n",
       " 'good': 154,\n",
       " 'lives': 155,\n",
       " 'kind': 156,\n",
       " 'most': 157,\n",
       " 'also': 158,\n",
       " 'america': 159,\n",
       " 'shaped': 160,\n",
       " 'side': 161,\n",
       " 'called': 162,\n",
       " 'each': 163,\n",
       " 'words': 164,\n",
       " 'done': 165,\n",
       " 'color': 166,\n",
       " 'mammal': 167,\n",
       " 'force': 168,\n",
       " 'flowers': 169,\n",
       " 'leaves': 170,\n",
       " 'means': 171,\n",
       " 'cloth': 172,\n",
       " 'wood': 173,\n",
       " 'thick': 174,\n",
       " 'put': 175,\n",
       " 'information': 176,\n",
       " 'sea': 177,\n",
       " 'substance': 178,\n",
       " 'showing': 179,\n",
       " 'eat': 180,\n",
       " 'much': 181,\n",
       " 'object': 182,\n",
       " 'device': 183,\n",
       " 'them': 184,\n",
       " 'set': 185,\n",
       " 'tree': 186,\n",
       " 'show': 187,\n",
       " 'heavy': 188,\n",
       " 'open': 189,\n",
       " 'high': 190,\n",
       " 'hold': 191,\n",
       " 'position': 192,\n",
       " 'look': 193,\n",
       " 'especially': 194,\n",
       " 'life': 195,\n",
       " 'been': 196,\n",
       " 'living': 197,\n",
       " 'easily': 198,\n",
       " 'point': 199,\n",
       " 'yellow': 200,\n",
       " 'causing': 201,\n",
       " 'sharp': 202,\n",
       " 'so': 203,\n",
       " 'ocean': 204,\n",
       " 'come': 205,\n",
       " 'quality': 206,\n",
       " 'become': 207,\n",
       " 'asia': 208,\n",
       " 'worn': 209,\n",
       " 'against': 210,\n",
       " 'because': 211,\n",
       " 'power': 212,\n",
       " 'right': 213,\n",
       " 'purpose': 214,\n",
       " 'bird': 215,\n",
       " 'equal': 216,\n",
       " 'government': 217,\n",
       " 'narrow': 218,\n",
       " 'closely': 219,\n",
       " 'grow': 220,\n",
       " 'only': 221,\n",
       " 'before': 222,\n",
       " 'inside': 223,\n",
       " 'round': 224,\n",
       " 'whose': 225,\n",
       " 'shape': 226,\n",
       " 'tail': 227,\n",
       " 'see': 228,\n",
       " 'down': 229,\n",
       " 'too': 230,\n",
       " 'law': 231,\n",
       " 'written': 232,\n",
       " 'change': 233,\n",
       " 'earth': 234,\n",
       " 'human': 235,\n",
       " 'action': 236,\n",
       " 'this': 237,\n",
       " 'ground': 238,\n",
       " 'may': 239,\n",
       " 'brown': 240,\n",
       " 'get': 241,\n",
       " 'sometimes': 242,\n",
       " 'fish': 243,\n",
       " 'tool': 244,\n",
       " 'space': 245,\n",
       " 'front': 246,\n",
       " 'happening': 247,\n",
       " 'unit': 248,\n",
       " 'young': 249,\n",
       " 'series': 250,\n",
       " 'disease': 251,\n",
       " 'black': 252,\n",
       " 'job': 253,\n",
       " 'does': 254,\n",
       " 'keep': 255,\n",
       " 'four': 256,\n",
       " 'cut': 257,\n",
       " 'sides': 258,\n",
       " 'language': 259,\n",
       " 'again': 260,\n",
       " 'writing': 261,\n",
       " 'go': 262,\n",
       " 'near': 263,\n",
       " 'fur': 264,\n",
       " 'male': 265,\n",
       " 'south': 266,\n",
       " 'paper': 267,\n",
       " 'hand': 268,\n",
       " 'pointed': 269,\n",
       " 'chemical': 270,\n",
       " 'coming': 271,\n",
       " 'help': 272,\n",
       " 'along': 273,\n",
       " 'red': 274,\n",
       " 'moving': 275,\n",
       " 'neck': 276,\n",
       " 'size': 277,\n",
       " 'given': 278,\n",
       " 'hair': 279,\n",
       " 'first': 280,\n",
       " 'larger': 281,\n",
       " 'carry': 282,\n",
       " 'was': 283,\n",
       " 'attached': 284,\n",
       " 'covered': 285,\n",
       " 'pain': 286,\n",
       " 'will': 287,\n",
       " 'there': 288,\n",
       " 'fruit': 289,\n",
       " 'eaten': 290,\n",
       " 'new': 291,\n",
       " 'doing': 292,\n",
       " 'bring': 293,\n",
       " 'top': 294,\n",
       " 'clothing': 295,\n",
       " 'close': 296,\n",
       " 'true': 297,\n",
       " 'grows': 298,\n",
       " 'full': 299,\n",
       " 'objects': 300,\n",
       " 'caused': 301,\n",
       " 'room': 302,\n",
       " 'instrument': 303,\n",
       " 'africa': 304,\n",
       " 'ability': 305,\n",
       " 'feet': 306,\n",
       " 'states': 307,\n",
       " 'united': 308,\n",
       " 'solid': 309,\n",
       " 'else': 310,\n",
       " 'protect': 311,\n",
       " 'activity': 312,\n",
       " 'quickly': 313,\n",
       " 'europe': 314,\n",
       " 'year': 315,\n",
       " 'important': 316,\n",
       " 'system': 317,\n",
       " 'several': 318,\n",
       " 'happen': 319,\n",
       " 'during': 320,\n",
       " 'dark': 321,\n",
       " 'control': 322,\n",
       " 'low': 323,\n",
       " \"person's\": 324,\n",
       " 'covering': 325,\n",
       " 'pieces': 326,\n",
       " 'special': 327,\n",
       " 'mouth': 328,\n",
       " 'next': 329,\n",
       " 'main': 330,\n",
       " 'type': 331,\n",
       " 'held': 332,\n",
       " 'ship': 333,\n",
       " 'known': 334,\n",
       " 'little': 335,\n",
       " 'face': 336,\n",
       " 'energy': 337,\n",
       " 'business': 338,\n",
       " 'wild': 339,\n",
       " 'well': 340,\n",
       " 'toward': 341,\n",
       " 'event': 342,\n",
       " 'study': 343,\n",
       " 'member': 344,\n",
       " 'insects': 345,\n",
       " 'mind': 346,\n",
       " 'whole': 347,\n",
       " 'single': 348,\n",
       " 'mammals': 349,\n",
       " 'sounds': 350,\n",
       " 'game': 351,\n",
       " 'clear': 352,\n",
       " 'family': 353,\n",
       " 'trees': 354,\n",
       " 'female': 355,\n",
       " 'numeral': 356,\n",
       " 'day': 357,\n",
       " 'cover': 358,\n",
       " 'central': 359,\n",
       " 'mark': 360,\n",
       " 'meaning': 361,\n",
       " 'wide': 362,\n",
       " 'difficult': 363,\n",
       " 'capital': 364,\n",
       " 'above': 365,\n",
       " 'blood': 366,\n",
       " 'handle': 367,\n",
       " 'comes': 368,\n",
       " 'city': 369,\n",
       " 'roman': 370,\n",
       " 'boat': 371,\n",
       " 'length': 372,\n",
       " 'bright': 373,\n",
       " 'sweet': 374,\n",
       " 'movement': 375,\n",
       " 'similar': 376,\n",
       " 'under': 377,\n",
       " 'either': 378,\n",
       " 'times': 379,\n",
       " 'attention': 380,\n",
       " 'wrong': 381,\n",
       " 'green': 382,\n",
       " 'deep': 383,\n",
       " 'machine': 384,\n",
       " 'woman': 385,\n",
       " 'public': 386,\n",
       " 'giving': 387,\n",
       " 'smell': 388,\n",
       " 'causes': 389,\n",
       " 'spelling': 390,\n",
       " 'heat': 391,\n",
       " 'seeds': 392,\n",
       " 'wings': 393,\n",
       " 'loud': 394,\n",
       " 'curved': 395,\n",
       " 'elements': 396,\n",
       " 'danger': 397,\n",
       " 'house': 398,\n",
       " 'present': 399,\n",
       " 'needed': 400,\n",
       " 'center': 401,\n",
       " 'seen': 402,\n",
       " 'forward': 403,\n",
       " 'while': 404,\n",
       " 'less': 405,\n",
       " 'support': 406,\n",
       " 'smooth': 407,\n",
       " 'turn': 408,\n",
       " 'raised': 409,\n",
       " 'formed': 410,\n",
       " 'outside': 411,\n",
       " 'tall': 412,\n",
       " 'name': 413,\n",
       " 'feel': 414,\n",
       " 'natural': 415,\n",
       " 'skill': 416,\n",
       " 'line': 417,\n",
       " 'manner': 418,\n",
       " 'gas': 419,\n",
       " 'lower': 420,\n",
       " 'sun': 421,\n",
       " 'born': 422,\n",
       " 'meat': 423,\n",
       " 'stone': 424,\n",
       " 'likely': 425,\n",
       " 'looks': 426,\n",
       " 'gives': 427,\n",
       " 'feelings': 428,\n",
       " 'thought': 429,\n",
       " 'tiny': 430,\n",
       " 'played': 431,\n",
       " 'speak': 432,\n",
       " 'built': 433,\n",
       " 'horse': 434,\n",
       " 'bad': 435,\n",
       " 'sudden': 436,\n",
       " 'container': 437,\n",
       " 'opening': 438,\n",
       " 'goods': 439,\n",
       " 'musical': 440,\n",
       " 'warm': 441,\n",
       " 'physical': 442,\n",
       " 'distance': 443,\n",
       " 'say': 444,\n",
       " 'both': 445,\n",
       " 'middle': 446,\n",
       " 'events': 447,\n",
       " 'world': 448,\n",
       " 'relating': 449,\n",
       " 'property': 450,\n",
       " 'stop': 451,\n",
       " 'shows': 452,\n",
       " 'direction': 453,\n",
       " 'play': 454,\n",
       " 'works': 455,\n",
       " 'common': 456,\n",
       " 'man': 457,\n",
       " 'edge': 458,\n",
       " 'numbers': 459,\n",
       " 'find': 460,\n",
       " 'real': 461,\n",
       " 'value': 462,\n",
       " 'god': 463,\n",
       " 'american': 464,\n",
       " 'pleasant': 465,\n",
       " 'straight': 466,\n",
       " 'religious': 467,\n",
       " 'plural': 468,\n",
       " 'wind': 469,\n",
       " 'forms': 470,\n",
       " 'matter': 471,\n",
       " 'fear': 472,\n",
       " 'care': 473,\n",
       " 'apart': 474,\n",
       " 'longer': 475,\n",
       " 'own': 476,\n",
       " 'how': 477,\n",
       " 'harm': 478,\n",
       " 'school': 479,\n",
       " 'free': 480,\n",
       " 'foot': 481,\n",
       " 'fact': 482,\n",
       " 'fire': 483,\n",
       " 'just': 484,\n",
       " 'pay': 485,\n",
       " 'shiny': 486,\n",
       " 'completely': 487,\n",
       " 'birds': 488,\n",
       " 'bottom': 489,\n",
       " 'holding': 490,\n",
       " 'better': 491,\n",
       " 'oneself': 492,\n",
       " 'shell': 493,\n",
       " 'religion': 494,\n",
       " 'figure': 495,\n",
       " 'quick': 496,\n",
       " 'book': 497,\n",
       " 'enough': 498,\n",
       " 'smaller': 499,\n",
       " 'structure': 500,\n",
       " 'humans': 501,\n",
       " 'groups': 502,\n",
       " 'tropical': 503,\n",
       " 'taken': 504,\n",
       " 'result': 505,\n",
       " 'every': 506,\n",
       " 'desire': 507,\n",
       " 'drink': 508,\n",
       " 'respect': 509,\n",
       " 'understand': 510,\n",
       " 'separate': 511,\n",
       " 'child': 512,\n",
       " 'wet': 513,\n",
       " 'complete': 514,\n",
       " 'materials': 515,\n",
       " 'gray': 516,\n",
       " 'three': 517,\n",
       " 'degree': 518,\n",
       " 'contains': 519,\n",
       " 'home': 520,\n",
       " 'left': 521,\n",
       " 'including': 522,\n",
       " 'medicine': 523,\n",
       " 'damage': 524,\n",
       " 'closed': 525,\n",
       " 'mythology': 526,\n",
       " 'stick': 527,\n",
       " 'tube': 528,\n",
       " 'colors': 529,\n",
       " 'anything': 530,\n",
       " 'dogs': 531,\n",
       " 'rough': 532,\n",
       " 'knowledge': 533,\n",
       " 'rank': 534,\n",
       " \"earth's\": 535,\n",
       " 'bodies': 536,\n",
       " 'ears': 537,\n",
       " 'looking': 538,\n",
       " 'glass': 539,\n",
       " 'his': 540,\n",
       " 'produce': 541,\n",
       " 'canada': 542,\n",
       " 'plastic': 543,\n",
       " 'taste': 544,\n",
       " 'northern': 545,\n",
       " 'leather': 546,\n",
       " 'speech': 547,\n",
       " 'horses': 548,\n",
       " 'period': 549,\n",
       " 'opinion': 550,\n",
       " 'nose': 551,\n",
       " 'these': 552,\n",
       " 'countries': 553,\n",
       " 'sense': 554,\n",
       " 'moves': 555,\n",
       " 'rock': 556,\n",
       " 'blue': 557,\n",
       " 'upper': 558,\n",
       " 'mostly': 559,\n",
       " 'eyes': 560,\n",
       " 'circle': 561,\n",
       " 'prefix': 562,\n",
       " 'uses': 563,\n",
       " 'pull': 564,\n",
       " 'teeth': 565,\n",
       " 'hollow': 566,\n",
       " 'taking': 567,\n",
       " 'picture': 568,\n",
       " 'her': 569,\n",
       " 'filled': 570,\n",
       " 'hands': 571,\n",
       " 'located': 572,\n",
       " 'were': 573,\n",
       " 'fall': 574,\n",
       " 'ends': 575,\n",
       " 'blade': 576,\n",
       " 'measure': 577,\n",
       " 'tell': 578,\n",
       " 'practice': 579,\n",
       " 'careful': 580,\n",
       " 'bears': 581,\n",
       " 'mass': 582,\n",
       " 'strength': 583,\n",
       " 'voice': 584,\n",
       " 'travel': 585,\n",
       " 'years': 586,\n",
       " 'instance': 587,\n",
       " 'art': 588,\n",
       " 'below': 589,\n",
       " 'dry': 590,\n",
       " 'noise': 591,\n",
       " 'sleep': 592,\n",
       " 'letter': 593,\n",
       " 'culture': 594,\n",
       " 'goal': 595,\n",
       " 'soil': 596,\n",
       " 'higher': 597,\n",
       " 'break': 598,\n",
       " 'behavior': 599,\n",
       " 'spread': 600,\n",
       " 'once': 601,\n",
       " 'then': 602,\n",
       " 'plan': 603,\n",
       " 'statement': 604,\n",
       " 'future': 605,\n",
       " 'loose': 606,\n",
       " 'expected': 607,\n",
       " 'run': 608,\n",
       " 'insect': 609,\n",
       " 'across': 610,\n",
       " 'cattle': 611,\n",
       " 'symbol': 612,\n",
       " 'element': 613,\n",
       " 'within': 614,\n",
       " 'think': 615,\n",
       " 'wall': 616,\n",
       " 'hole': 617,\n",
       " 'vehicle': 618,\n",
       " 'dead': 619,\n",
       " 'adult': 620,\n",
       " 'decoration': 621,\n",
       " 'sugar': 622,\n",
       " 'express': 623,\n",
       " 'need': 624,\n",
       " 'pass': 625,\n",
       " 'region': 626,\n",
       " 'regular': 627,\n",
       " 'rules': 628,\n",
       " 'lack': 629,\n",
       " 'rope': 630,\n",
       " 'greek': 631,\n",
       " 'night': 632,\n",
       " 'wooden': 633,\n",
       " 'catch': 634,\n",
       " 'orange': 635,\n",
       " 'connected': 636,\n",
       " 'working': 637,\n",
       " 'rain': 638,\n",
       " 'agreement': 639,\n",
       " 'far': 640,\n",
       " 'east': 641,\n",
       " 'level': 642,\n",
       " 'remove': 643,\n",
       " 'suddenly': 644,\n",
       " 'cry': 645,\n",
       " 'correct': 646,\n",
       " 'eggs': 647,\n",
       " 'serious': 648,\n",
       " 'weight': 649,\n",
       " 'outer': 650,\n",
       " 'grain': 651,\n",
       " 'letters': 652,\n",
       " 'store': 653,\n",
       " 'last': 654,\n",
       " 'carrying': 655,\n",
       " 'mother': 656,\n",
       " 'frame': 657,\n",
       " 'poisonous': 658,\n",
       " 'sign': 659,\n",
       " 'honor': 660,\n",
       " 'grass': 661,\n",
       " 'kept': 662,\n",
       " 'areas': 663,\n",
       " 'official': 664,\n",
       " 'holds': 665,\n",
       " 'keeping': 666,\n",
       " 'suffix': 667,\n",
       " 'evergreen': 668,\n",
       " 'grown': 669,\n",
       " 'ice': 670,\n",
       " 'sport': 671,\n",
       " 'feathers': 672,\n",
       " 'oil': 673,\n",
       " 'arabic': 674,\n",
       " 'story': 675,\n",
       " 'thread': 676,\n",
       " 'character': 677,\n",
       " 'nature': 678,\n",
       " 'evil': 679,\n",
       " 'pink': 680,\n",
       " 'meal': 681,\n",
       " 'milk': 682,\n",
       " 'purple': 683,\n",
       " 'going': 684,\n",
       " 'rounded': 685,\n",
       " 'cooked': 686,\n",
       " 'growing': 687,\n",
       " 'produced': 688,\n",
       " 'view': 689,\n",
       " 'spoken': 690,\n",
       " 'carefully': 691,\n",
       " 'write': 692,\n",
       " 'return': 693,\n",
       " 'fresh': 694,\n",
       " 'goes': 695,\n",
       " 'start': 696,\n",
       " 'buildings': 697,\n",
       " 'takes': 698,\n",
       " 'old': 699,\n",
       " 'thinking': 700,\n",
       " 'know': 701,\n",
       " 'mixture': 702,\n",
       " 'flower': 703,\n",
       " 'farm': 704,\n",
       " 'bar': 705,\n",
       " 'suffering': 706,\n",
       " 'deer': 707,\n",
       " 'love': 708,\n",
       " 'foods': 709,\n",
       " 'interest': 710,\n",
       " 'anger': 711,\n",
       " 'cells': 712,\n",
       " 'church': 713,\n",
       " 'usual': 714,\n",
       " 'points': 715,\n",
       " 'alphabet': 716,\n",
       " 'science': 717,\n",
       " 'fine': 718,\n",
       " 'hot': 719,\n",
       " 'easy': 720,\n",
       " 'situation': 721,\n",
       " 'breathe': 722,\n",
       " 'highest': 723,\n",
       " 'specific': 724,\n",
       " 'course': 725,\n",
       " 'pair': 726,\n",
       " 'music': 727,\n",
       " 'forth': 728,\n",
       " 'sky': 729,\n",
       " 'services': 730,\n",
       " 'cutting': 731,\n",
       " 'sheep': 732,\n",
       " 'those': 733,\n",
       " 'injury': 734,\n",
       " 'join': 735,\n",
       " 'snow': 736,\n",
       " 'carried': 737,\n",
       " 'placed': 738,\n",
       " 'now': 739,\n",
       " 'sentence': 740,\n",
       " 'authority': 741,\n",
       " 's': 742,\n",
       " 'hit': 743,\n",
       " 'military': 744,\n",
       " 'river': 745,\n",
       " 'surprise': 746,\n",
       " 'effort': 747,\n",
       " 'until': 748,\n",
       " 'powder': 749,\n",
       " 'salt': 750,\n",
       " 'pattern': 751,\n",
       " 'cold': 752,\n",
       " 'happy': 753,\n",
       " 'married': 754,\n",
       " 'active': 755,\n",
       " 'firm': 756,\n",
       " 'roof': 757,\n",
       " 'walk': 758,\n",
       " 'fat': 759,\n",
       " 'cooking': 760,\n",
       " 'range': 761,\n",
       " 'baked': 762,\n",
       " 'arms': 763,\n",
       " 'items': 764,\n",
       " 'illness': 765,\n",
       " 'dog': 766,\n",
       " 'court': 767,\n",
       " 'town': 768,\n",
       " 'strip': 769,\n",
       " 'laws': 770,\n",
       " 'abbreviation': 771,\n",
       " 'field': 772,\n",
       " 'possible': 773,\n",
       " 'throw': 774,\n",
       " 'stiff': 775,\n",
       " 'crops': 776,\n",
       " 'ball': 777,\n",
       " 'english': 778,\n",
       " 'pole': 779,\n",
       " 'almost': 780,\n",
       " 'acts': 781,\n",
       " 'door': 782,\n",
       " 'hurt': 783,\n",
       " 'rule': 784,\n",
       " 'lived': 785,\n",
       " 'persons': 786,\n",
       " 'broken': 787,\n",
       " 'draw': 788,\n",
       " 'slowly': 789,\n",
       " 'branch': 790,\n",
       " 'section': 791,\n",
       " 'sure': 792,\n",
       " 'clean': 793,\n",
       " 'charge': 794,\n",
       " 'ships': 795,\n",
       " 'electricity': 796,\n",
       " 'actions': 797,\n",
       " 'reach': 798,\n",
       " 'verb': 799,\n",
       " 'collection': 800,\n",
       " 'willing': 801,\n",
       " 'pressure': 802,\n",
       " 'experience': 803,\n",
       " 'angry': 804,\n",
       " 'ancient': 805,\n",
       " 'formal': 806,\n",
       " 'source': 807,\n",
       " 'friendly': 808,\n",
       " 'ruler': 809,\n",
       " 'title': 810,\n",
       " 'getting': 811,\n",
       " 'ready': 812,\n",
       " 'stream': 813,\n",
       " 'hooves': 814,\n",
       " 'beginning': 815,\n",
       " 'speaking': 816,\n",
       " 'ago': 817,\n",
       " 'joined': 818,\n",
       " 'flow': 819,\n",
       " 'lines': 820,\n",
       " 'importance': 821,\n",
       " 'father': 822,\n",
       " 'stand': 823,\n",
       " 'joy': 824,\n",
       " 'speed': 825,\n",
       " 'loss': 826,\n",
       " 'holes': 827,\n",
       " 'considered': 828,\n",
       " 'metals': 829,\n",
       " 'weapon': 830,\n",
       " 'leave': 831,\n",
       " 'call': 832,\n",
       " 'behind': 833,\n",
       " 'fight': 834,\n",
       " 'beyond': 835,\n",
       " 'motion': 836,\n",
       " 'largest': 837,\n",
       " 'colored': 838,\n",
       " 'supply': 839,\n",
       " 'flesh': 840,\n",
       " 'fasten': 841,\n",
       " 'greater': 842,\n",
       " 'covers': 843,\n",
       " 'carries': 844,\n",
       " 'design': 845,\n",
       " 'steady': 846,\n",
       " 'trouble': 847,\n",
       " 'jewelry': 848,\n",
       " 'garden': 849,\n",
       " 'floor': 850,\n",
       " 'trained': 851,\n",
       " 'opposite': 852,\n",
       " 'birth': 853,\n",
       " 'days': 854,\n",
       " 'layer': 855,\n",
       " 'strings': 856,\n",
       " 'waves': 857,\n",
       " 'even': 858,\n",
       " 'sand': 859,\n",
       " 'six': 860,\n",
       " 'healthy': 861,\n",
       " 'stomach': 862,\n",
       " 'bill': 863,\n",
       " 'vegetable': 864,\n",
       " 'subject': 865,\n",
       " 'waste': 866,\n",
       " 'western': 867,\n",
       " 'horns': 868,\n",
       " 'fixed': 869,\n",
       " 'changing': 870,\n",
       " 'printed': 871,\n",
       " 'chest': 872,\n",
       " 'cotton': 873,\n",
       " 'proper': 874,\n",
       " 'weak': 875,\n",
       " 'meant': 876,\n",
       " 'eye': 877,\n",
       " 'wire': 878,\n",
       " 'wheels': 879,\n",
       " 'among': 880,\n",
       " 'truth': 881,\n",
       " 'upon': 882,\n",
       " 'products': 883,\n",
       " 'juicy': 884,\n",
       " 'furniture': 885,\n",
       " 'powerful': 886,\n",
       " 'push': 887,\n",
       " 'southern': 888,\n",
       " 'idea': 889,\n",
       " 'had': 890,\n",
       " 'bacteria': 891,\n",
       " 'useful': 892,\n",
       " 'arm': 893,\n",
       " 'based': 894,\n",
       " 'base': 895,\n",
       " 'west': 896,\n",
       " 'spring': 897,\n",
       " 'britain': 898,\n",
       " 'slightly': 899,\n",
       " 'shrub': 900,\n",
       " 'saying': 901,\n",
       " 'tip': 902,\n",
       " 'breed': 903,\n",
       " 'breathing': 904,\n",
       " 'bed': 905,\n",
       " 'native': 906,\n",
       " 'waist': 907,\n",
       " 'talk': 908,\n",
       " 'facts': 909,\n",
       " 'wound': 910,\n",
       " 'learn': 911,\n",
       " 'cannot': 912,\n",
       " 'stories': 913,\n",
       " 'marks': 914,\n",
       " 'surrounded': 915,\n",
       " 'pleasure': 916,\n",
       " 'activities': 917,\n",
       " 'players': 918,\n",
       " 'oxygen': 919,\n",
       " 'send': 920,\n",
       " 'chance': 921,\n",
       " 'meet': 922,\n",
       " 'serving': 923,\n",
       " 'mainly': 924,\n",
       " 'eating': 925,\n",
       " 'belonging': 926,\n",
       " 'appear': 927,\n",
       " 'needs': 928,\n",
       " 'protection': 929,\n",
       " 'war': 930,\n",
       " 'breaking': 931,\n",
       " 'tissue': 932,\n",
       " 'divided': 933,\n",
       " 'kill': 934,\n",
       " 'pulled': 935,\n",
       " 'added': 936,\n",
       " 'bend': 937,\n",
       " 'growth': 938,\n",
       " 'fly': 939,\n",
       " 'doubt': 940,\n",
       " 'decide': 941,\n",
       " 'necessary': 942,\n",
       " 'belief': 943,\n",
       " 'indian': 944,\n",
       " 'allowed': 945,\n",
       " 'attack': 946,\n",
       " 'mollusks': 947,\n",
       " 'problem': 948,\n",
       " 'question': 949,\n",
       " 'rocks': 950,\n",
       " 'buy': 951,\n",
       " 'organ': 952,\n",
       " 'praise': 953,\n",
       " 'service': 954,\n",
       " 'burning': 955,\n",
       " 'board': 956,\n",
       " 'mixing': 957,\n",
       " 'believed': 958,\n",
       " 'temperature': 959,\n",
       " 'branches': 960,\n",
       " 'organization': 961,\n",
       " 'shells': 962,\n",
       " 'lungs': 963,\n",
       " 'platform': 964,\n",
       " 'case': 965,\n",
       " 'itself': 966,\n",
       " 'wife': 967,\n",
       " 'painful': 968,\n",
       " 'unusual': 969,\n",
       " 'thrown': 970,\n",
       " 'rodents': 971,\n",
       " 'leg': 972,\n",
       " 'try': 973,\n",
       " 'square': 974,\n",
       " 'road': 975,\n",
       " 'believe': 976,\n",
       " 'lions': 977,\n",
       " 'cat': 978,\n",
       " 'unable': 979,\n",
       " 'ideas': 980,\n",
       " 'alone': 981,\n",
       " 'citizen': 982,\n",
       " 'eastern': 983,\n",
       " 'everything': 984,\n",
       " 'ceremony': 985,\n",
       " 'atlantic': 986,\n",
       " 'moon': 987,\n",
       " 'location': 988,\n",
       " 'reason': 989,\n",
       " 'appearance': 990,\n",
       " 'office': 991,\n",
       " 'machines': 992,\n",
       " 'sad': 993,\n",
       " 'read': 994,\n",
       " 'death': 995,\n",
       " 'film': 996,\n",
       " 'pigs': 997,\n",
       " 'includes': 998,\n",
       " 'flour': 999,\n",
       " 'strike': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simpDefWordIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'at one time in the past; formerly.\\xa0'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_train_y_RAW[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = full_train_y_RAW[0].split(' ')[0]\n",
    "print(t)\n",
    "simpDefWordIndex.get(t, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    [input_seq, output_seq[:, :-1]],\n",
    "    output_seq[:, 1:],\n",
    "    batch_size=64,\n",
    "    epochs=100,\n",
    "    validation_split=0.2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1024, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1082, in compute_loss\n        return self.compiled_loss(\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/keras/losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/keras/losses.py\", line 284, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/keras/losses.py\", line 2004, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/keras/backend.py\", line 5532, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 98) and (None, 98, 8992) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 13\u001b[0m\n\u001b[1;32m      1\u001b[0m callbacks \u001b[39m=\u001b[39m [\n\u001b[1;32m      2\u001b[0m     keras\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mModelCheckpoint(\n\u001b[1;32m      3\u001b[0m         filepath\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mconvnet_from_scratch.keras\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m         save_best_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m      5\u001b[0m         monitor\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m ]\n\u001b[1;32m      9\u001b[0m \u001b[39m#encoding_token, decoding_token, embedding_dim, latent_dim\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m     14\u001b[0m     [train_x, train_y],\n\u001b[1;32m     15\u001b[0m     train_y,\n\u001b[1;32m     16\u001b[0m     batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m,\n\u001b[1;32m     17\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[1;32m     18\u001b[0m     validation_data\u001b[39m=\u001b[39;49m([val_x, val_y],\n\u001b[1;32m     19\u001b[0m                      val_y)\n\u001b[1;32m     20\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filec3kvxqe5.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1024, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1082, in compute_loss\n        return self.compiled_loss(\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/keras/losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/keras/losses.py\", line 284, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/keras/losses.py\", line 2004, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/home/tyler/miniconda3/envs/tf/lib/python3.9/site-packages/keras/backend.py\", line 5532, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 98) and (None, 98, 8992) are incompatible\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"convnet_from_scratch.keras\",\n",
    "        save_best_only=True,\n",
    "        monitor=\"val_loss\")\n",
    "]\n",
    "\n",
    "\n",
    "#encoding_token, decoding_token, embedding_dim, latent_dim\n",
    "\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    [train_x, train_y],\n",
    "    train_y,\n",
    "    batch_size=32,\n",
    "    epochs=10,\n",
    "    validation_data=([val_x, val_y],\n",
    "                     val_y)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  637  2426 11496  3327     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0]]\n",
      "['west african ceremonial trumpet']\n",
      "1/1 [==============================] - 1s 692ms/step\n",
      "[[4.601204   0.6426386  0.4150675  0.40080303 0.38807482 0.34474388\n",
      "  0.26806122 0.21995524 0.20366837 0.19732386 0.1939196  0.19190133\n",
      "  0.1907119  0.19002315 0.18962704 0.18939781 0.18926352 0.18918328\n",
      "  0.18913437 0.18910387 0.18908437 0.18907186 0.1890636  0.18905792\n",
      "  0.18905383 0.18904997 0.18904269 0.18902415 0.18899679 0.18897948\n",
      "  0.18897302 0.18897094 0.18897009 0.1889697  0.18896946 0.18896925\n",
      "  0.18896914 0.18896905 0.18896894 0.18896885 0.1889688  0.18896873\n",
      "  0.18896867 0.18896861 0.18896858 0.18896855 0.18896852 0.1889685\n",
      "  0.1889685  0.18896846 0.18896843 0.18896835 0.18896775 0.18896377\n",
      "  0.18893932 0.18880296 0.18828127 0.18750417 0.187121   0.18701869\n",
      "  0.18699653 0.18699196 0.18699102 0.1869908  0.1869907  0.18699068\n",
      "  0.18699065 0.18699068 0.1869907  0.1869907  0.18699074 0.18699077\n",
      "  0.18699084 0.18699087 0.18699096 0.18699105 0.1869911  0.18699121\n",
      "  0.18699135 0.1869915  0.18699168 0.18699187 0.18699208 0.18699226\n",
      "  0.18699257 0.18699287 0.18699317 0.18699354 0.18699396 0.18699443\n",
      "  0.1869949  0.1869954  0.18699604 0.18699661 0.18699728 0.18699801\n",
      "  0.1869988  0.18699957]]\n",
      "['']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "data, tokens, tokenizer = convertTextToNumbers([\"West African ceremonial trumpet\"],defTokenizer, padding=len(train_x[0]))\n",
    "print(data)\n",
    "print(defTokenizer.sequences_to_texts(data))\n",
    "\n",
    "inputdata = np.array(data).reshape(1, -1)\n",
    "\n",
    "outputdata = np.zeros(shape=(1, len(train_y[0])))\n",
    "outputdata[0,0] = simpDefTokenizer.word_index['start']\n",
    "#outputdata = np.reshape(outputdata, (1,1))\n",
    "\n",
    "\n",
    "newSentence = model.predict([inputdata, outputdata])\n",
    "print(newSentence)\n",
    "print(simpDefTokenizer.sequences_to_texts(newSentence))\n",
    "\n",
    "# Assuming you have already preprocessed and tokenized the sentence\n",
    "#test_sentence = \"the cat jumped over the moon\"\n",
    "#test_sentence_tokens = tokenizer.texts_to_sequences([test_sentence])[0]\n",
    "#test_sentence_tokens = np.array(test_sentence_tokens).reshape(1, -1)\n",
    "\n",
    "# Initialize the decoder input with the start token\n",
    "#decoder_input = np.zeros(shape=(1, max_summary_len))\n",
    "#decoder_input[0, 0] = summary_tokenizer.word_index['start']\n",
    "\n",
    "# Reshape the decoder input to have a length of 1\n",
    "#decoder_input = np.reshape(decoder_input, (1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_y[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting/Plotting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[123], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m accuracy \u001b[39m=\u001b[39m history\u001b[39m.\u001b[39;49mhistory[\u001b[39m\"\u001b[39;49m\u001b[39maccuracy\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[1;32m      3\u001b[0m val_accuracy \u001b[39m=\u001b[39m history\u001b[39m.\u001b[39mhistory[\u001b[39m\"\u001b[39m\u001b[39mval_accuracy\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m      4\u001b[0m loss \u001b[39m=\u001b[39m history\u001b[39m.\u001b[39mhistory[\u001b[39m\"\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'accuracy'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "accuracy = history.history[\"accuracy\"]\n",
    "val_accuracy = history.history[\"val_accuracy\"]\n",
    "loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "epochs = range(1, len(accuracy) + 1)\n",
    "plt.plot(epochs, accuracy, \"bo\", label=\"Training accuracy\")\n",
    "plt.plot(epochs, val_accuracy, \"b\", label=\"Validation accuracy\")\n",
    "plt.title(\"Training and validation accuracy\")\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "a675ecb475794e98cc508edff942b4df7efb840dcd0161848ec7416e01ca0315"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
